최초 제출 성공 9버전 0.56722 베이스 라인 뚫음. 현재 로그 미적용상태
11버전 로그 변환 적용함 0.50628 이상치들이 많은 그래프라 적당히 캐어 됨

데이터 재확인 및 eda과정을 다시 거친 이후, 첫 제출 0.51322 로그 적용상태임.
기존 9버전~11버전에서는 datetime을 쪼개지 않아 12개의 컬럼으로 했었으나
이번에는 쪼개서 컬럼 17개인 상태로 실험에 들어갔음.
그 직후, autogloun으로 600리밋 걸고 620초 가량 학습 시킨 이후 제출함.
0.48725점 획득.

추후 같은 로직으로 2~3번 정도 더 반복학습 시킨 이후 제출함.
오히려 점수가 떨어지는 상황에 직면. 0.50060점 획득.
(추가학습 코드를 안 넣었으므로 재학습 결과 떨어진 것->기존csv파일은 학습파일에 있음)
이런 거로 보아 맨 처음으로 다시 돌아가는 게 맞는 듯 함. 
또는 추가 규칙이나 룰을 다시 찾던지 맨처음 다시 돌아가서
컬럼이나 eda부터 다시 보는 게 맞는 듯 함.

02/05 점심시간 이후에, 오토글론 돌려서 로그 좀 보고
오토글론이 뽑아내는 로그나 데이터 서머리에서
새로운 컬럼들 확인 예정. 어떤 것들을 조합하는지 확인할 필요가 있음.

오토글론으로 돌려서 기존 12개+가공해둔 피쳐5개 해서 17개 였는데
스태킹 피쳐로 5개가 추가되어버렸다.
기존 23개 였던 것으로 기억하는데 limit:600 -> limit1200 수정으로 다시 6개로 추가해볼셈이다.


관찰 및 문제 인식: 풍속이 0이면 실제데이터가 아니다 오류라는 생성형ai의 말.
-> 의문: 바람 부는 날이 많을 수도 있는 것 아닌가. (나)

배경지식 조사 및 문헌연구: 
-> 풍속 데이터를 보면 이상한 점이 발견 된다고 함. (그래프로 확인할 필요성이 있음)
-> 보통 자연 현상은 풍속이 $0.1, 0.5, 1.2$ 이런 식으로 연속적으로 나타나야 한다고 하고,
그런데 이 데이터는 0에 엄청나게 많은 데이터가 몰려 있고, 그다음 숫자가 갑자기 6이나 7부터 시작하는 경우가 많습니다. 즉, **"아주 약하게 부는 바람"**을 측정기가 잡아내지 못하고 그냥 0으로 기록해버렸을 가능성이 매우 높다는 뜻이죠. 까지가 생성형 ai의 의견.

가설 설정: 그런데 맑은 날에는 0일 수도 있는 것 아닌가? -> 단, 폭풍우 치는 날엔 0일 수가 없다.
  
탐구/실험 설계 및 수행: 아까 오토글론으로 확인 했던 23개의 컬럼 기반으로 조작변인, 통제변인, 종속 변인 설정필요. ->  

결과 해석 및 결론 도출:

결과 공유 및 보고:


확증편향의 오류:

관찰 및 문제 인식: 그래프 관찰 결과 -> 새벽4시~새벽6시는 대여량이 0에 가깝고, 오후5시~오후7시는 대여량이 폭증한다.
 
결론 : 단, 풍속 40인 날은 대여량이 0에 수렴하는 것을 모델에게 인식시킨다. 
(풍속40 이상인 날을 그래프로 재확인 필요)  

그런데 풍속이 40이라고 대여량이 0에 수렴한다는 것은 어떻게 확신할 수 있는가. 
위의 결론이 오버피팅인지 아닌지 확인 필요.




for data in [train, test]:
    # 1. 일단 모두 '나머지(Others)'로 채워둡니다.
    data['time_session'] = 'Others'
    
    # 2. 새벽 4시 ~ 6시 (4, 5, 6시 포함) -> 'Dawn_Peak'
    data.loc[(data['hour'] >= 4) & (data['hour'] <= 6), 'time_session'] = 'Dawn_Peak'
    
    # 3. 오후 5시 ~ 7시 (17, 18, 19시 포함) -> 'Eve_Peak'
    data.loc[(data['hour'] >= 17) & (data['hour'] <= 19), 'time_session'] = 'Eve_Peak'

# 잘 들어갔는지 10개만 확인해볼까요?
train[['hour', 'time_session']].head(20)


# 새로 만든 그룹별로 대여량 평균 확인
train.groupby('time_session')['count'].mean()
